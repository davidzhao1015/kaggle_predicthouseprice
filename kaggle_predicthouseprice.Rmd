---
title: 'Kaggle project: House price regression'
author: "Xin (David) Zhao"
date: "Last edited `r format(Sys.time(), '%d %B %Y')`"
knit: (function(inputFile, encoding) {
      out_dir <- 'docs';
      rmarkdown::render(inputFile,
                        encoding=encoding,
                        output_file=file.path(dirname(inputFile), out_dir, 'index.html'))})
output:
  html_document:
    # theme: cosmo
    highlight: pygments
    df_print: paged
    toc: TRUE
    toc_float: TRUE
    collapsed: FALSE
    number_sections: TRUE
    fig_width: 7
    fig_height: 6
    fig_caption: TRUE
editor_options: 
  markdown: 
    wrap: 72
# bibliography: references.bib
---

<html>

<head>

```{=html}
<style>

h1{
 color: #055C9D;
 font-family: Georgia;
 font-size: 200%
}


h2{
 color: #055C9D;
 font-family: helvetica;
 font-size: 150%
}

h3{
 color: #055C9D;  
 font-family: helvetica;
 font-size: 120%; 
}

p {
 color: #333333;
 font-family: helvetica;
 font-size: 100%;
}

.blackbox {
  padding: 1em;
  background: green;
  color: black;
  border: 2px solid orange;
  border-radius: 10px;
}

.center {
  text-align: center;
}

</style>
```
</head>

</html>

```{r setup, include = FALSE}
# set options for the entire document 
knitr::opts_chunk$set(fig.align = 'center', 
                      fig.height=6, fig.width=8,
                      dev="png",
                      echo=TRUE, #display code in output document 
                      error=FALSE,
                      collapse = FALSE, 
                      message=FALSE) #stop render when error occurs   
```

## Project aim

This is a Kaggle competition project. The purpose of this project is to
predict house prices in Ames, Iowa from available variables with machine
learning algorithms.

Personal learning purpose: - Reinforce machine learning knowledge -
Practice using caret package and workflow - Learn advanced feature
engineering - Learn new algorithms

## Workflow

Follow the machine learning workflow of caret R package.

0.  Load libraries
1.  Import data
2.  Exploratory data analysis
3.  Preprocess data - Create dummy variables - Zero- and near
    zero-variance - Impute missing data - Label encoding - Drop highly
    correlated variables - Linear dependencies - Centering and scaling -
    Transform predictors - Remove outliers
4.  Feature selection\
5.  Feature engineering\*
6.  Data splitting (skip)
7.  Train and tune models - Lasso regression model - XGBoost model -
    Random forest
8.  Evaluate performance

## R code

### Load R libraries

Load necessary libraries

```{r libraries, warning=FALSE}

library(tidyverse) 
library(caret) 
library(factoextra) # visualize k-means 
library(RANN)
library(mgcv) # generalized addictive model using splines - non-linear regression
library(ranger)  # random forest 
library(h2o) # gradient boosting machines 
library(WVPlots)  # draw gain curve plots 
library(xgboost)  # eXtreme gradient boosting 

```

### Import data sets

```{r import data}

# unzip downloaded file 

unzip(zipfile = "./house-prices-advanced-regression-techniques.zip",
      files = NULL,
      exdir = "./raw-data")

list.files("./raw-data")

```

The row datasets contain four files: - `data_description.txt` -
`sample_submission.csv` - `test.csv` - `train.csv`

Import and inspect train set 

```{r csv files}

# read in train.csv

train_df <- read.csv(file = "./raw-data/train.csv",
                     header = T)

head(train_df)  # view first rows 


# data structure 
str(train_df)

dim(train_df)

```

The train set contains `r dim(train_df)[1]` observations and
`r dim(train_df)[2]` variables.

Find description of response and explanatory variables at the Kaggle [website](https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/data). 

Import and inspect test set 

```{r test set}

# load test set 
test_df <- read.csv(file = "./raw-data/test.csv",
                    header = T)

head(test_df) # view first rows 

```

The test set contains `r dim(test_df)[1]` observations and
`r dim(test_df)[2]` variables.


### Exploratory data analysis 

#### Distribution of response variable in the train set 

The target variable to predict is `SalePrice` - the property's sale price in dollars.  

```{r  EDA-response-var}
# distribution of the response variable in the train set 
ggplot(data = train_df, aes(x = SalePrice/1000)) +
        geom_histogram(binwidth = 10, fill = "royalblue", alpha = 0.8) +
        scale_x_continuous(name = "Sale price in thousand dollars",
                           breaks = seq(1, 800, by=100),
                           labels = paste(seq(1, 800, by=100), "K", sep = "")) +
        geom_vline(aes(xintercept = 163), linetype = "dashed", color = "orange", size = 1)

        
```
The dashed line in the above histogram indicates the median of the sale prices in the train set. 


The response variable in the train set is left skewed. The average is 180K and median 163K. 

```{r summary-stats-response-var}

# summary stats 
summary(train_df$SalePrice) # median < mean 

# check if any missing values 
sum(is.na(train_df$SalePrice))  # print 0 

```

### Numeric and categorical variables

```{r numeric-var}

# put Id column to row names in train set 
train_df_id  <- train_df %>% 
  mutate(Id = paste("W", Id, sep = "")) %>%  # add "W" next to Id 
  column_to_rownames("Id")

dim(train_df_id) 

colnames_id <- colnames(train_df_id) 

```
The train set has 79 independent variables plus one response variable for 1460 samples. 


```{r}

# identify numeric variables and variables with >10 unique values 
var_unique <- sapply(train_df_id, function(x) length(unique(x))) %>% 
    as.data.frame() 

var_factor <- sapply(train_df_id, function(x) is.character(x)) %>% 
    as.data.frame() %>% 
    rownames_to_column("variables")

var_types <- cbind(var_unique, var_factor)

# rename columns 
colnames(var_types) <- c("unique_count", "variable", "is_char") 

head(var_types)

var_types <- var_types %>% 
  select(variable, unique_count, is_char) 


# extract variables with unique values more than 10 & not categorical variables - numeric variables 
is_num_var <- var_types %>% 
  filter(unique_count >= 10 & is_char == 0) %>% 
  pull(variable)

is_num_var

is_num_var2 <- is_num_var[-which(is_num_var == "SalePrice")]  # exclude the response variable 

is_num_var2 

```
25 numeric variables other than the response variable `SalePrice`. 



```{r category variable}

# identify categorical variables with no more than 10 unique values or is_character true 
is_fact_var <- var_types %>% 
  filter(unique_count < 10 | is_char == 1) %>% 
  pull(variable)

is_fact_var   # view variable names 

length(is_fact_var) # print 54 

```


```{r}

# check if any variable left 
colnames_id[-which(colnames_id %in% c(is_num_var2, is_fact_var))] 

```

Scatter plots to show relationship between numeric variables and the response variable, `SalePrice` 

```{r top-numeric-variables, warning=F}  

caret::featurePlot(x = train_df_id[ ,is_num_var2],  # 24 numeric variables 
                   y = train_df_id$SalePrice,
                   plot = "Scatter",
                   layout = c(4,7)) 

```

Investigate description statistics of independent numeric variables. 

```{r description stats numeric variables}

# investigate mean, median and NA in numeric variables including SalePrice 
summary(train_df_id[ ,is_num_var]) 

```
Highly skewed (substantial difference between median and mean) independent numeric variables:
`MasVnrArea`
`BsmtFinSF2`
`X2ndFlrSF`
`LowQualFinSF`
`WoodDeckSF`
`EnclosedPorch`
`X3SsnPorch`
`ScreenPorch`
`MiscVal`

Numeric variables have NAs:
`LotFrontage`
`MasVnrArea`
`GarageYrBlt` 

### Categrorical variables - EDA 

```{r subset-factor}

# covert character variables to factors 
train_df_fact  <- train_df_id %>% 
  dplyr::select(all_of(is_fact_var)) %>%   # subset 54 non-numeric variables and a response variable 
  mutate_all(., as.factor)  %>% # convert character variables to factors 
  bind_cols(., SalePrice = train_df_id$SalePrice)   # bind columns 
  
# structure of the resulting data frame 
str(train_df_fact)


```

Subset 54 independent factors and the response variable `SalePrice` following by correlation analysis. 


### Relationship between factors and the response variable 

#### Binary factors
Identify top factor variables associated with `SalePrice`. Use non-parameter [Kruskal-Wallis test](https://en.wikipedia.org/wiki/Kruskal%E2%80%93Wallis_one-way_analysis_of_variance#:~:text=Allen%20Wallis)%2C%20or%20one%2D,for%20comparing%20only%20two%20groups.) for multiple-class variables, while using [Mann-Whitney U test](https://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U_test) to binary-class variables. 

Use purrr package to apply function to columns of the data frame, referring to the [instruction](https://rpubs.com/faiazrmn/purrr_map_map2)

```{r binary vs response var}

# extract binary variables
is_binary <- train_df_fact %>%
        purrr::map_dfr(\(train_df_fact) length(levels(train_df_fact))) %>%
        gather(key = "factor_variable", value = "levels") %>%
        filter(levels == 2) %>%
        pull(factor_variable)

length(is_binary) # print 4 

# apply Wilcox test to each variables
train_df_fact_l2 <- train_df_fact %>%
        select(all_of(is_binary), SalePrice)

response_var <- train_df_fact_l2$SalePrice %>% as.data.frame()

binary_var <- train_df_fact_l2 %>% select(-SalePrice)

wilcox_fact_lv2 <- map2(binary_var, response_var, ~wilcox.test(.y ~ .x)) 


# extract p-value and significant factors 
wilcox_fact_lv2_df <- do.call(rbind, wilcox_fact_lv2) %>%
        as.data.frame() %>%
        rownames_to_column("variable") %>%
        select(variable, p.value) %>%
        filter(p.value <= 0.05) %>%
        pull(variable)

wilcox_fact_lv2_df # significant variable names 

```
Among the binary factors, `Alley` and `CentralAir` are significantly associated with the response variable. 


#### Multi-class factors 

```{r multiple-class-var-KW} 

# extract multi-class variables
is_multiclass <- train_df_fact %>%
        purrr::map_dfr(\(train_df_fact) length(levels(train_df_fact))) %>%
        gather(key = "factor_variable", value = "levels") %>%
        filter(levels > 2) %>%
        pull(factor_variable)

length(is_multiclass)  # print 50 

# apply kruskal-wallis test to each variables
train_df_fact_multi <- train_df_fact %>%
        select(all_of(is_multiclass), SalePrice)

response_var <- train_df_fact_multi$SalePrice  %>% as.data.frame()

multiclass_var <- train_df_fact_multi %>% select(-SalePrice)

wilcox_fact_multi <- map2(multiclass_var, response_var, ~kruskal.test(.y ~ .x))

# extract p-value and significant variables
wilcox_fact_multi_df <- do.call(rbind, wilcox_fact_multi) %>%
        as.data.frame() %>%
        rownames_to_column("variable") %>%
        select(variable, p.value) %>%
        filter(p.value <= 0.05) %>%
        pull(variable)

length(wilcox_fact_multi_df)  # 43 variables significant 

```
Summarize statistical results from correlation analysis between factors and the response variable, `SalePrice`. 

```{r summary factor corr}

# combine significant factors names, binary and multi-class 
sig_factors <- c(wilcox_fact_lv2_df, wilcox_fact_multi_df) 

length(sig_factors)  # 45 significant factors in total  

# summary 
factor_sig_overall <- train_df_fact %>%
  purrr::map_dfr(\(train_df_fact) length(levels(train_df_fact))) %>%
  gather(key = "factor_variable", value = "levels") %>% 
  mutate(is_significant = case_when(factor_variable %in% sig_factors == 1 ~ "yes",
                            factor_variable %in% sig_factors == 0 ~ "no"))  %>% 
  mutate(is_significant = as.factor(is_significant))
  
# factor_sig_overall # print the resulting data frame 
factor_sig_overall %>% 
  count(levels, sort = T)  


# factor with 15 classes 
factor_sig_overall %>% 
  filter(levels == 15)


```
In the table, `levels` represents class numbers of the factors. Majority factors have 4-5 classes. `Exterior1st` has 15 unique classes. 



### Dummy variable

Use `dummyVars` function in `caret` package to generate a complete set of dummy variables from multiple factors. 

```{r subset sig factors}

# subset significant factors from train set 

# train_df_fact_sig <- train_df_fact %>% 
#         select(all_of(wilcox_fact_lv2_df), 
#                all_of(wilcox_fact_multi_df),
#                SalePrice)
# 
# 
# dim(train_df_fact_sig) 


# subset numeric variables 
train_df_num <- train_df_id[ ,is_num_var2] 

# combine numeric variables and factors 
train_df2 <- cbind(train_df_fact, train_df_num)  


```
The resulting dataset has 37 significant factors other than the response variable `SalePrice`. 

The function `model.matrix` creates a design (or model) matrix. [R documentation](https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/model.matrix) provides detailed information regarding the function. 


```{r dummy-var}

# head(model.matrix(SalePrice ~., data = train_df_fact_sig)) 
dummies_train <- dummyVars(~., data = train_df2,
                           fullRank = TRUE,
                           sep = "_")  
dummies_train 

dummies_train_df <- data.frame(predict(dummies_train, newdata = train_df2)) 


dim(train_df2)  # 80 variables 

dim(dummies_train_df)  # resulting train set with 281 variables 

```

As indicated by the caret package vignette, there is no intercept and each factor has a dummy variable for each level, so this parameterization may not be useful for some model functions, such as `lm`. 


### Near-zero variance 

According to the caret package documentation, a variable is considered the near-zero variance when it meets the conditions as follows, 

- "frequency ratio" is greater than a pre-specified threshold
- "unique value percentage" is less than a threshold 

The [website](https://topepo.github.io/caret/pre-processing.html#creating-dummy-variables) provide detailed explanation regarding near-zero variance.  


Identify zero- and near-zero variance variables, or either. 

```{r nzv}

# near-zero variance 
nzv <- nearZeroVar(dummies_train_df, saveMetrics = F) 

# drop nzv variables 
dummies_train_nzv <- dummies_train_df[,-nzv] 

dim(dummies_train_df)  # 281 variables 

dim(dummies_train_nzv)  # 118 variables 

```


### Highly correlated variables  

```{r highly-cor-var, collapse=TRUE}

fl_train_cor <- cor(dummies_train_nzv) # pairwise correlation  

# summary(fl_train_cor[upper.tri(fl_train_cor)]) # upper triangle of correlations matrix before the removal 

# replace NA with 0
fl_train_cor2 <- fl_train_cor %>% replace(is.na(.), 0) 

# index of highly correlated variables 
highcorvar <- caret::findCorrelation(fl_train_cor2, cutoff = .75)   

highcorvar2 <- highcorvar[highcorvar != which(colnames(dummies_train_nzv) == "SalePrice")]  

# remove the highly correlated variables in the train set 
dummies_train_nzv2 <- dummies_train_nzv %>% 
        select(!all_of(highcorvar2))  # drop highly correlated variables 

dim(dummies_train_nzv2)  # 100 variables in the resulting train set  

```



### Imuptation 

Caret package tutorial introduces two methods to impute missing values, K-nearest neighbors and bagged trees. 

The caret website provides detailed explanation. 

In this project, I used K-nearest neighbors to impute the missingness, if any. 

```{r imputation}

# distribution of missing values in data 
miss_value <- sapply(dummies_train_nzv2, function(x) mean(is.na(x))) %>% as.data.frame() 

colnames(miss_value) <- "missing_percent"

miss_value2 <- miss_value %>% 
  rownames_to_column("variable") %>% 
  mutate(missing_percent = round(missing_percent, 2)) %>% 
  arrange(desc(missing_percent)) 

# NA in independent variables in the train set 
miss_value2

# top variables with NA 
top10_var_missing <- miss_value2 %>% 
  filter(missing_percent > 0.4) %>% 
  pull(variable) 


# drop variables with substantial missing values 
dummies_train_missing <- dummies_train_nzv2 %>% 
  select(-all_of(top10_var_missing)) 

dim(dummies_train_missing)  # 92 variables left in the resulting train set 



# ggplot bar plot for variables with missingness 
miss_value2 %>% 
  filter(missing_percent != 0) %>% 
  ggplot(aes(x = reorder(variable, missing_percent),  # reorder variable by missing percentages  
           y= missing_percent)) +
  geom_bar(stat = "identity", fill = "royalblue") + 
  coord_flip() +
  ggtitle("Variables with missingness in the train set") +
  labs(y ="Percentage", x= "")

```



```{r knn impute}

# # apply k-nearest method to impute data 
# impute_knn <- preProcess(dummies_train_missing,
#                          method = "knnImpute") 
# 
# impute_knn
# 
# 
# # train set after KNN imputation 
# dummies_train_impute <- predict(impute_knn, newdata = dummies_train_missing) 


# I encountered an error when running the KNN impute method. I found a Stack Exchange post said that "the problem you run into is that knnImpute requires at least as many samples in your data without missing values as you have specified with the k parameter for the k-nearest-neighbors." 

```


### Feature selection 

The [tutorial](https://topepo.github.io/caret/feature-selection-using-univariate-filters.html) of caret package provides an overview of various methods for feature selection:
- Wrapper 
  - recursive feature elimination 
  - genetic algorithms 
  - simulated annealing 
- Filter 
  - univariate filters 

#### Feature selection - PCA

Up next, perform unsupervised machine learning to selected numeric variables, 
- k-means clustering 
- hierarchical clustering 
- PCA 
In addition, compare two clustering assignments. 


Conduct k-means clustering analysis on the filtered variables in the train set. Refer to instructions on Datacamp and the website, [Datanovia](https://www.datanovia.com/en/lessons/k-means-clustering-in-r-algorith-and-practical-examples/). 

```{r kmeans-cluster}

# # replace NA with 0
# dummies_train_nzv3 <- dummies_train_impute %>% replace(is.na(.), 0)
# 
# # scale 
# dummies_train_nzv3_scale <- scale(dummies_train_impute) 
# 
# 
# 
# # implement k-means 
# set.seed(123)
# 
# kmeans_train <- kmeans(dummies_train_nzv3_scale, 
#                        centers = 3,  # group the data into 3 clusters 
#                        nstart = 20)  # generate 20 initial configuration 
# 
# summary(kmeans_train)
# 
# 
# # distribution of k-means clustering 
# table(kmeans_train$cluster)
# 
# 
# # # calculate mean of the response variable, SalePrice by the clusters 
# # aggregate(dummies_train_nzv, 
# #           by = list(cluster = kmeans_train$cluster), 
# #           mean) %>% 
# #         select(cluster, SalePrice)

```

The Cluster 2 has the greatest average compared to Cluster 1 and 3. 

Visualize kmeans clustering with `fviz_cluster` function in `functoextra` package. Refer to the online [instruction](https://uc-r.github.io/kmeans_clustering)


```{r viz kmeans}

# fviz_cluster(kmeans_train, 
#              data = dummies_train_nzv3_scale, 
#              geom= "point") 

```



Determine optimal cluster with the Elbow plot. Refer to the online [codes](https://uc-r.github.io/kmeans_clustering#elbow)

```{r best-cluster}

# set.seed(123)
# 
# # function to compute total within-cluster sum of square 
# wss <- function(k) {
#   kmeans(dummies_train_nzv3_scale, k, nstart = 10 )$tot.withinss
# }
# 
# # Compute and plot wss for k = 1 to k = 15
# k.values <- 1:15
# 
# # extract wss for 2-15 clusters
# wss_values <- map_dbl(k.values, wss)
# 
# plot(k.values, wss_values,
#        type="b", pch = 19, frame = FALSE, 
#        xlab="Number of clusters K",
#        ylab="Total within-clusters sum of squares")

```


Run PCA on the filtered variables in the train-set. 

```{r PCA}

set.seed(123)

train_pca_rm.na <- dummies_train_missing %>% replace(is.na(.), 0) # replace NA with 0 

pr.train <- prcomp(x = train_pca_rm.na, scale =T, center = T) 

summary(pr.train)


```


```{r biplot pca}

# # ggplot2-based plot for PCA analysis
fviz_pca_biplot(pr.train,
                repel = F,
                col.ind = "grey",
                label = "var",
                select.var = list(contrib = 10)) # show top 10 variables 

```

Extract loading from PCA analysis using `factoextra` package. 

```{r PCA loadings}

# # extract contribution of variables 
pca_var <- factoextra::get_pca_var(pr.train)  

# top 10 variables that explain variations of data
top_var_pca <- pca_var$contrib  %>%
  as.data.frame() %>%
  arrange(desc(abs(Dim.1))) %>%
  rownames_to_column("Variable") %>%
  head(12) %>%
  pull(Variable)

top_var_pca

```


#### Feature selection - univariate analysis

```{r univariate}

# pair-wise correlation among 90 variables 
res_num <- cor(dummies_train_missing)  # pearson correlation method 

colnames(res_num) <- 1:ncol(res_num) 

# extract index for significant variables 
top_num_index <- res_num %>%
        as.data.frame() %>%
        rownames_to_column("variable") %>%
        mutate(row_index = 1:nrow(.)) %>%
        gather(key = "col_index", value = "rho", -c("row_index", "variable")) %>%
        filter(variable == "SalePrice") %>% 
        filter(abs(rho) >= 0.4) %>% 
        arrange(desc(abs(rho))) %>%
        pull(col_index) %>% 
        as.numeric()

top_univar <- rownames(res_num)[top_num_index]  # top variable names 

top_univar

```

Alternatively, use `sbf` function in the `caret` package to implement univariate filtering. Follow the code example in the caret [tutorial](https://topepo.github.io/caret/feature-selection-using-univariate-filters.html).  

```{r sbf-univar-filter}

filterCtrl <- sbfControl(functions = rfSBF,
                         method = "repeatedcv",
                         repeats = 5) 

set.seed(123)

predictors <- dummies_train_missing %>%  select(-SalePrice) %>% replace(is.na(.), 0) 

rfWithinFilter <- sbf(predictors, 
                      dummies_train_missing$SalePrice,
                      sbfControl = filterCtrl)

rfWithinFilter 


# selected variables of importance 
sbf_vars <- rfWithinFilter$variables[1]  %>% 
  as.data.frame() %>% 
  pull(selectedVars)


```


#### Feature selection - Recursive feature elimination (wrapper filter)

Try alternative ways to select informative features but not include them all. 

Looking for an optimal combination of variables, I try the feature selection method, Recursive Feature Elimination. The caret [tutorial](https://topepo.github.io/caret/recursive-feature-elimination.html) talks more details about this method. 


```{r rfe}

# linear regression 

set.seed(123)

subsets <- c(1:5, 10, 15, 20, 25)

ctrl_rfe <- rfeControl(functions = lmFuncs,  # linear regression 
                       method = "repeatedcv",   # resampling 
                       repeats = 5,
                       verbose = FALSE) 

lmProfile <- rfe(predictors, # predictors candidates
                 dummies_train_missing$SalePrice,  # response variable 
                 sizes = subsets,
                 rfeControl = ctrl_rfe
                 )

lmProfile

caret::predictors(lmProfile)  # 91 variables 

# plot 
trellis.par.set(caretTheme())
plot(lmProfile, type = c("g", "o"))


```

RMSE keeps decreasing with increasing number of variable. There is an "elbow" around 20 variables. 


Run the RFE algorithm on Random Forest model 

```{r rfe-rf}

# customize a function to implement Random Forest in RFE algorithm 
rfRFE <-  list(summary = defaultSummary,
               fit = function(x, y, first, last, ...){
                 library(randomForest)
                 randomForest(x, y, importance = first, ...)
                 },
               pred = function(object, x)  predict(object, x),
               rank = function(object, x, y) {
                 vimp <- varImp(object)
                 vimp <- vimp[order(vimp$Overall,decreasing = TRUE),,drop = FALSE]
                 vimp$var <- rownames(vimp)                  
                 vimp
                 },
               selectSize = pickSizeBest,
               selectVar = pickVars)


# change parameters in ctrl_rfe
ctrl_rfe$functions <- rfRFE  # random forest 

ctrl_rfe$returnResamp <- "all"  # save all the re-sampling results across subset sizes 

set.seed(123)

rfProfile <- rfe(predictors, # predictors candidates
                 dummies_train_missing$SalePrice,  # response variable  
                 sizes = subsets, 
                 rfeControl = ctrl_rfe)


rfProfile


# plot
trellis.par.set(caretTheme())
plot(rfProfile, type = c("g", "o"))



```


### Train models 

Set up re-sampling method. Use [k-fold cross validation](https://rpubs.com/cliex159/881990) strategy. 

```{r cross validation}

fitControl <- trainControl(method = "cv", # cross validation 
                           number = 5,  # k = 5 
                           verboseIter = TRUE)  

```


```{r select predictors}

# features derived from the univariate analysis 
top_univar 

# features derived from PCA 
top_var_pca 

# features derived from sbf - univariate filtering 
sbf_vars 

```


```{r subset features}

# subset important features from train set  
dummies_train_missing2 <- 
  dummies_train_missing %>% 
  select(all_of(sbf_vars), SalePrice)  

# deal with missing values 
dummies_train_missing3 <- dummies_train_missing2 %>% replace(is.na(.), 0)

head(dummies_train_missing3) 

```

Train models:
- Generalized linear model 
- Linear regression 
- GAM model (Generalized additive model)
- Random Forest 

```{r train models, message=FALSE, results='hide'}

set.seed(123)  # ensure reproducibility 


# Generalized linear model
glm_train <- train(SalePrice ~ .,
                   data = dummies_train_missing3,
                   method = "glm",
                   trControl = fitControl)

glm_train # train model


# Linear regression 
lm_train <- train(SalePrice ~ .,
                   data = dummies_train_missing3,
                   method = "lm",
                   trControl = fitControl)

lm_train  # model info


# GAM 
gam_train <- train(SalePrice ~ .,
                   data = dummies_train_missing3,
                   method = "gam",
                   trControl = fitControl)

gam_train # model information



# Random forest 
rf_train <- train(SalePrice ~ .,
                   data = dummies_train_missing3,
                   method = "rf",
                   trControl = fitControl) 


rf_train # model information  


# eXtreme Gradient boosting   - takes very long time to run 
# xgb_train <- train(SalePrice ~ .,
#                    data = dummies_train_missing3,
#                    method = "xgbDART",
#                    trControl = fitControl) 
# 
# xgb_train # model information

```


### Graphically evaluate models 

Use different plots to evaluate models, 
- Prediction vs. ground truth plot
- Residual plot
- Gain curve

```{r plot models}

# copy the train set 
dummies_train_missing4 <- dummies_train_missing3 

# prediction on train set with 4 models 
dummies_train_missing4$pred_lm <- predict(lm_train) # lm
dummies_train_missing4$pred_glm <- predict(glm_train) # glm
dummies_train_missing4$pred_gam <- predict(gam_train)  # gam
dummies_train_missing4$pred_rf <- predict(rf_train)  # rf

# calculate residuals 
dummies_train_missing4 <- dummies_train_missing4 %>%
  mutate(residual_lm = pred_lm - SalePrice) %>%
  mutate(residual_glm = pred_glm - SalePrice) %>%
  mutate(residual_gam = pred_gam - SalePrice) %>%
  mutate(residual_rf = pred_rf - SalePrice)

```


```{r pred-truth plot}
# prediction vs. truth plots
pred_truth_df <- dummies_train_missing4 %>%
  select(pred_lm, pred_glm, pred_gam, pred_rf, SalePrice) %>%
  gather(key = "models", value = "prediction", -SalePrice)

ggplot(pred_truth_df, aes(x= SalePrice, y= prediction, color = models)) +
  geom_point() +
  geom_abline(slope = 1, intercept = 0,
              linetype = "dashed", color = "royalblue", linewidth = 1)+
  facet_wrap(vars(models)) +
  ggtitle("Prediction vs. groud truth in the train set")

```



```{r residual plot}

# residual plot 
res_truth_df <- dummies_train_missing4 %>%
  select(residual_lm, residual_glm, residual_gam, residual_rf, SalePrice) %>%
  gather(key = "models", value = "residual", -SalePrice) %>%
  mutate(model = str_sub(.$models, start = 10)) %>%
  select(-models)

ggplot(res_truth_df, aes(x=SalePrice, y= residual, color = model))+
  geom_point(alpha = 0.8) +
  geom_hline(yintercept = 0,
             linetype = "dashed", color = "royalblue", size = 1) +
  facet_wrap(vars(model))

```


Draw the gain curves using `WVPlots` [package](https://www.rdocumentation.org/packages/WVPlots/versions/1.3.2/topics/GainCurvePlot). The data camp course, "Supervised machine learning regression" explains the gain curves in more detailed. 

```{r gain curves}

# random forest - gain curve 
GainCurvePlot(dummies_train_missing4, 
              "pred_rf", 
              "SalePrice", 
              "Random Forest model for home price")

```

In the gain curve, the x-axis is sale prices in model-sorted order (decreasing). The y-axis is the fraction of total accumulatd  sale price. The wizard curve represents the perfect model. 


### Select the best model

Apply `postResample` function in caret package to estimate measures of model performance, including

- RMSE
- Rsquared 
- MAE 

```{r model performance metrics}

rf_perf <- postResample(pred = dummies_train_missing4$pred_rf, obs = dummies_train_missing4$SalePrice) %>% as.data.frame() # rf

lm_perf <- postResample(pred = dummies_train_missing4$pred_lm, obs = dummies_train_missing4$SalePrice) %>% as.data.frame() # lm

gam_perf <-  postResample(pred = dummies_train_missing4$pred_gam, obs = dummies_train_missing4$SalePrice) %>% as.data.frame()  # gam

glm_perf <-  postResample(pred = dummies_train_missing4$pred_glm, obs = dummies_train_missing4$SalePrice) %>% as.data.frame() # glm


# merge above data frames 
merg_perf <- data.frame(rf = rf_perf,
                        lm = lm_perf,
                        gam = gam_perf,
                        glm = glm_perf)

colnames(merg_perf) <- c("rf", "lm", "gam", "glm")  # rename columns 

merg_perf <- merg_perf %>%
  rownames_to_column("measure")  # row to column  

merg_perf <- merg_perf %>%
  gather(key = "model", value = "performance", -measure) %>%
  mutate(performance = round(performance, 2))

# bar plot to compare single value by measures
ggplot(merg_perf, aes(x = model, y = performance)) +
  geom_bar(aes(fill = model), stat = "identity", position = "dodge") +
  facet_wrap(vars(measure), scales = "free_y")



```

The random forest model outperforms counterparts based on three performance measures. Thus pick the random forest model to predict test set. 


### Preprocess the test set

```{r preprocess test set}

# convert character variables to factor variables 
test_df2 <- test_df %>% 
        mutate_if(is.character, as.factor) %>% 
        mutate(Id = paste("W", as.character(Id), sep = "")) %>%  # keep id as character variables 
        column_to_rownames("Id")  

# numeric variables 
test_df_num <- test_df2[ ,is_num_var2]  

# convert character variables to factors 
test_df_fact  <- test_df2 %>% 
  dplyr::select(all_of(is_fact_var)) %>%   # subset 54 non-numeric variables and a response variable 
  mutate_all(., as.factor) # convert character variables to factors 

# combine numeric variables and factors 
test_df_comb <- cbind(test_df_fact, test_df_num)  




# double-check if any factor only has one level 
factor_test <- sapply(test_df_comb, function(x) length(levels(x))) %>% 
  as.data.frame() %>% 
  rownames_to_column("variable") 

colnames(factor_test) <- c("variable", "level") 

factor_test %>% 
  filter(level == 1) %>% 
  pull(variable)

# drop the factor, 'Utilities'
test_df_comb2 <- test_df_comb %>% 
  select(-Utilities) 



# create dummy variables 
dummy_test <- dummyVars(~., data = test_df_comb2,
                           fullRank = TRUE,
                           sep = "_")  

dummy_test_df <- data.frame(predict(dummy_test, 
                                    newdata = test_df_comb2)) 

```


### Predict the test set 

```{r predict on test set}

# extract the final model of Random forest 
rf_train_finalmod <- rf_train$finalModel  

# replace missing values in the test set with 0 
dummy_test_df_rm.na <- dummy_test_df %>% replace(is.na(.), 0) 

# predict on the test set 
dummy_test_df_rm.na$SalePrice_pred <- predict(rf_train_finalmod,  # optimal Random Forest model 
                                              dummy_test_df_rm.na)  # test set with replacing NAs 

```


```{r saleprice test and train}

# histogram plots 
dummies_train_missing4 %>% 
  ggplot(aes(x= pred_rf))+
  geom_histogram(color = "blue", fill="blue", alpha = 0.1) +  # prediction in train set 
  geom_histogram(aes(x = SalePrice), color = "yellow", fill= "yellow", alpha = 0.1) +  # truth in train set 
  geom_histogram(data = dummy_test_df_rm.na, # prediction in test set  
                 aes(x = SalePrice_pred), 
                 color = "red", fill="red", alpha = 0.1) +
  scale_x_log10()  # log10 scale 



```


#### Feature importance based on Random Forest model

Which features are most predictive? Use `varImp` function in the `caret` package to estimate variable ranking in either model-dependent and model-independent metrics. 

The [tutorial](https://topepo.github.io/caret/variable-importance.html) of caret package provides detailed explanation for `varImp` function. 

```{r feature importance}

# Random Forest dependent metrics  
rfImp <- varImp(rf_train, 
                scale = T, # scale = F, avoids normalization  
                useModel = T)  

# alternatively, model independent metrics 
variable_Imp  <- varImp(rf_train, 
                        scale = T, # scale = F, avoids normalization  
                        useModel = FALSE)  # non-specific   


# # plot with base R 
# plot(rfImp, top = 10)

```

Visualize variable rankings based on two metrics using `ggplot2`. 

```{r plot variable ranking}

# bar plot 
rfImp_df <- rfImp$importance %>% 
  rownames_to_column("variable") 

rfImp_df %>% 
  arrange(desc(Overall)) %>% 
  head(12) %>% 
  ggplot(aes(y=Overall, x=reorder(variable, Overall))) +
  geom_bar(stat = "identity", fill = "royalblue") + 
  coord_flip() +
  ggtitle("Feature importance based on Random Forest model") +
  labs(x = "", y="")


```

Detailed information for each variables:
- `OverllQual`: Overall material and finish quality
- `X1stFlrSF`: unknown 
- `GarageCars_3`: Size of garage in car capacity 
- `GarageArea`: Size of garage in square feet
- `YearBuilt`: Original construction date
- `TotRmsAbvGrd`: Total rooms above grade (does not include bathrooms)
- `YearRemodAdd`: Remodel date 


