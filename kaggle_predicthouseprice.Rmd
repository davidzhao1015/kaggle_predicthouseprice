---
title: 'Kaggle project: House price regression'
author: "Xin (David) Zhao"
date: "Last edited `r format(Sys.time(), '%d %B %Y')`"
knit: (function(inputFile, encoding) {
      out_dir <- 'docs';
      rmarkdown::render(inputFile,
                        encoding=encoding,
                        output_file=file.path(dirname(inputFile), out_dir, 'index.html'))})
output:
  html_document:
    # theme: cosmo
    highlight: pygments
    df_print: paged
    toc: TRUE
    toc_float: TRUE
    collapsed: FALSE
    number_sections: TRUE
    fig_width: 7
    fig_height: 6
    fig_caption: TRUE
editor_options: 
  markdown: 
    wrap: 72
bibliography: references.bib
---

<html>

<head>

```{=html}
<style>

h1{
 color: #055C9D;
 font-family: Georgia;
 font-size: 200%
}


h2{
 color: #055C9D;
 font-family: helvetica;
 font-size: 150%
}

h3{
 color: #055C9D;  
 font-family: helvetica;
 font-size: 120%; 
}

p {
 color: #333333;
 font-family: helvetica;
 font-size: 100%;
}

.blackbox {
  padding: 1em;
  background: green;
  color: black;
  border: 2px solid orange;
  border-radius: 10px;
}

.center {
  text-align: center;
}

</style>
```
</head>

</html>

```{r setup, include = FALSE}
# set options for the entire document 
knitr::opts_chunk$set(fig.align = 'center', 
                      fig.height=6, fig.width=8,
                      dev="png",
                      echo=TRUE, #display code in output document 
                      error=FALSE,
                      collapse = FALSE, 
                      message=FALSE) #stop render when error occurs   
```


## Project aim

This is a Kaggle competition project. The purpose of this project is to predict house prices in Ames, Iowa from available variables with machine learning algorithms.


## Procedure outline 

0. Load libraries 
1. Import and explore data 
2. Explore some of the most important variables 
3. Preprocess data 
        - Missing data 
        - Label encoding 
        - Factorize variables 
4. Visualize important variables 
5. Find variables importance with Random Forest 
6. Feature engineering 
7. Prepare data for modeling 
        - Drop highly correalted variables 
        - Remove outliers
        - Skewness and normalize numeric predictors
        - Remove levels with few or no observatoins in train or test 
8. Deal with skewness of response variable 
9. Composing train and test sets 
10. Modeling
        - Lasso regression model 
        - XGBoost model 
        - Random forest 
11. Evaluate performance


## R code








d 