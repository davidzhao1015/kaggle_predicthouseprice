---
title: 'Kaggle project: House price regression'
author: "Xin (David) Zhao"
date: "Last edited `r format(Sys.time(), '%d %B %Y')`"
knit: (function(inputFile, encoding) {
      out_dir <- 'docs';
      rmarkdown::render(inputFile,
                        encoding=encoding,
                        output_file=file.path(dirname(inputFile), out_dir, 'index.html'))})
output:
  html_document:
    # theme: cosmo
    highlight: pygments
    df_print: paged
    toc: TRUE
    toc_float: TRUE
    collapsed: FALSE
    number_sections: TRUE
    fig_width: 7
    fig_height: 6
    fig_caption: TRUE
editor_options: 
  markdown: 
    wrap: 72
# bibliography: references.bib
---

<html>

<head>

```{=html}
<style>

h1{
 color: #055C9D;
 font-family: Georgia;
 font-size: 200%
}


h2{
 color: #055C9D;
 font-family: helvetica;
 font-size: 150%
}

h3{
 color: #055C9D;  
 font-family: helvetica;
 font-size: 120%; 
}

p {
 color: #333333;
 font-family: helvetica;
 font-size: 100%;
}

.blackbox {
  padding: 1em;
  background: green;
  color: black;
  border: 2px solid orange;
  border-radius: 10px;
}

.center {
  text-align: center;
}

</style>
```
</head>

</html>

```{r setup, include = FALSE}
# set options for the entire document 
knitr::opts_chunk$set(fig.align = 'center', 
                      fig.height=6, fig.width=8,
                      dev="png",
                      echo=TRUE, #display code in output document 
                      error=FALSE,
                      collapse = FALSE, 
                      message=FALSE) #stop render when error occurs   
```

## Project aim

This is a Kaggle competition project. The purpose of this project is to
predict house prices in Ames, Iowa from available variables with machine
learning algorithms.

Personal learning purpose: - Refresh machine learning knowledge -
Practice using caret package and workflow - Learn advanced feature
engineering - Learn math and principles for algorithms

## Workflow

Follow the machine learning workflow of caret R package.

0.  Load libraries
1.  Import data
2.  Exploratory data analysis
3.  Preprocess data - Create dummy variables - Zero- and near
    zero-variance - Impute missing data - Label encoding - Drop highly
    correlated variables - Linear dependencies - Centering and scaling -
    Transform predictors - Remove outliers
4.  Feature selection\
5.  Feature engineering\*
6.  Data splitting (skip)
7.  Train and tune models - Lasso regression model - XGBoost model -
    Random forest
8.  Evaluate performance

## R code

### Load R libraries

Load necessary libraries

```{r libraries, warning=FALSE}

library(tidyverse) 
library(caret) 

```

### Import data sets

```{r import data}

# unzip downloaded file 

unzip(zipfile = "./house-prices-advanced-regression-techniques.zip",
      files = NULL,
      exdir = "./raw-data")

list.files("./raw-data")

```

The row datasets contain four files: - `data_description.txt` -
`sample_submission.csv` - `test.csv` - `train.csv`

Import and inspect train set 

```{r csv files}

# read in train.csv

train_df <- read.csv(file = "./raw-data/train.csv",
                     header = T)

head(train_df)  # view first rows 


# data structure 
str(train_df)


dim(train_df)

```

The train set contains `r dim(train_df)[1]` observations and
`r dim(train_df)[2]` variables.

Find description of response and explanatory variables at the Kaggle [website](https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/data). 


Import and inspect test set 

```{r test set}

# load test set 
test_df <- read.csv(file = "./raw-data/test.csv",
                    header = T)

head(test_df)

```

The test set contains `r dim(test_df)[1]` observations and
`r dim(test_df)[2]` variables.

### Exploratory data analysis 

#### Distribution of response variable in the train set 

The target variable to predict is `SalePrice` - the property's sale price in dollars.  

```{r  EDA-response-var}

# distribution of the response variable in the train set 
ggplot(data = train_df, aes(x = SalePrice/1000)) +
        geom_histogram(binwidth = 10, fill = "royalblue", alpha = 0.8) +
        scale_x_continuous(name = "Sale price in thousand dollars",
                           breaks = seq(1, 800, by=100),
                           labels = paste(seq(1, 800, by=100), "K", sep = "")) +
        geom_vline(aes(xintercept = 163), linetype = "dashed", color = "orange", size = 1)
        

```
The dashed line in the above histogram indicates the median of the sale prices in the train set. 


The response variable in the train set is left skewed. The average is 180K and median 163K. 

```{r summary-stats-response-var}

# summary stats 
summary(train_df$SalePrice)

# check if any missing values 
sum(is.na(train_df$SalePrice))  

```

### Numeric variables

```{r numeric-var}

# subset numeric variables 
train_df_num <- train_df %>% 
        dplyr::select(where(is.numeric))  


# pick top numeric variables based on rho 

res_num <- cor(train_df_num, method = "spearman")  

colnames(res_num) <- 1:ncol(res_num)

top_num_index <- res_num %>% 
        as.data.frame() %>% 
        rownames_to_column("variable") %>% 
        mutate(row_index = 1:nrow(.)) %>% 
        gather(key = "col_index", value = "rho", -c("row_index", "variable")) %>% 
        filter(variable == "SalePrice") %>% 
        filter(abs(rho) >= 0.5) %>%
        pull(col_index) %>% 
        as.numeric

top_num_var <- rownames(res_num)[top_num_index]  # top variable names  


```

Subset top number variables

```{r top-numeric-variables} 

caret::featurePlot(x = train_df_num[ ,top_num_index],
                   y = train_df_num$SalePrice,
                   plot = "Scatter",
                   layout = c(4,3),
                   jitter = T) 



```

### Factor variables 











